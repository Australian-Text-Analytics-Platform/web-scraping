{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f28e34",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "Extracting text from websites requires you to do some web scraping, which can be done relatively simply with a library called Beautiful Soup in Python.\n",
    "\n",
    "**NOTE:** This notebook assumes that you're already familiar with using APIs as shown here: https://github.com/Australian-Text-Analytics-Platform/open-australia-api/blob/main/api.ipynb\n",
    "\n",
    "You don't need to know how to use APIs to do any web scraping. We are just using the information from that notebook to target which websites we will scrape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d94749c",
   "metadata": {},
   "source": [
    "## The Task\n",
    "\n",
    "Open Australia have saved parliamentary debates on their websites. You can find the latest ones here: <a href=\"https://www.openaustralia.org.au/debates/\">https://www.openaustralia.org.au/debates/</a>\n",
    "\n",
    "This notebook gets one of their webpages with a debate and scrapes the text from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6387ba7c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Skills:</b>\n",
    "<ul>    \n",
    "<li> Website scraping </li>\n",
    "</ul>    \n",
    "<br>\n",
    "<b>Skill Level:</b> Beginner/Intermediate\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28347e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we begin, let's make sure that we install all the requirements that we need\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b6ac7f",
   "metadata": {},
   "source": [
    "## Getting the Webpages to Scrape (Optional)\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Before Running the Next Block of Code</b> \n",
    "\n",
    "You will need an API key to run the next block of code. You can find out how here: <a href=\"https://github.com/Australian-Text-Analytics-Platform/open-australia-api/blob/main/api.ipynb\">API Notebook</a>\n",
    "</div>\n",
    "\n",
    " \n",
    "If you're not interested in using APIs, don't worry. You can skip running the following cell and run the rest of the notebook. We are simply using the Open Australia API because their website hosts parliamentary speeches and we are aiming to scrape the text from their webpages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd05ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define constants at the very beginning\n",
    "OA_API = 'http://www.openaustralia.org/api/'\n",
    "API_KEY = None  # add your key here as a string, eg 'RPLDbrHE9cPoEn2MIfQWfRcA' (with the quotes)\n",
    "OUTPUT_FORMAT = 'js'\n",
    "\n",
    "# Define a dictionary of parameters as arguments to the function\n",
    "params = dict()\n",
    "params['key'] = API_KEY\n",
    "params['output'] = OUTPUT_FORMAT\n",
    "\n",
    "# The function we are using is 'getRepresentatives' so we can fetch the politician's member_id\n",
    "my_function = 'getRepresentatives'\n",
    "\n",
    "# The full endpoint is the string: OA_API+my_function. In Python you can concatenate strings with '+' \n",
    "response = requests.get(OA_API+my_function, params=params)\n",
    "result = response.json()\n",
    "\n",
    "print('NUMBER OF PARLIAMENTARIANS:', len(result))\n",
    "\n",
    "# Loop through the results to find the relevant information\n",
    "for politician in result:\n",
    "    if politician['last_name'] == 'Bandt':\n",
    "        print('INFO ON BANDT:')\n",
    "        print(politician)\n",
    "        bandt = politician\n",
    "\n",
    "# Use the function getHansard\n",
    "my_function = 'getHansard'\n",
    "my_params = params        # require the old params, such as the api_key and the output type\n",
    "my_params['order'] = 'd'  # d for date; r for relevance; p for person\n",
    "\n",
    "# Bandt\n",
    "my_params['person'] = bandt['person_id']\n",
    "response = requests.get(OA_API+my_function, params=my_params)\n",
    "hansard_bandt = response.json()\n",
    "hansard_bandt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e13415",
   "metadata": {},
   "source": [
    "## Without Using the Open Australia API\n",
    "\n",
    "If you don't already have an API_KEY from Open Australia, then you can simply get the required 'hansard_bandt' data by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# We saved the required 'hansardt_bandt' data in a file called hansard_bandt.json that you can read.\n",
    "FILE = 'hansard_bandt.json'\n",
    "hansard_bandt = json.loads(open(FILE).read())\n",
    "\n",
    "# Print the output\n",
    "hansard_bandt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc9096",
   "metadata": {},
   "source": [
    "### Inspecting Your Data\n",
    "\n",
    "It's always a good idea to inspect your data. In this notebook you can do this by simply printing out the variables that you've defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5feb4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you're unsure about what kind of variable you have, you can always print out its type\n",
    "type(hansard_bandt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf3538c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Data Structure: dict</b> \n",
    "\n",
    "The dictionary or dict() is a useful data type that is a set of key-value pairs, which makes retrieving data very convenient.\n",
    "\n",
    "You can learn more about this data type here: <a href=\"https://docs.python.org/3/tutorial/datastructures.html#dictionaries\">Dictionaries</a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dcc114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['info', 'searchdescription', 'rows'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the dictionary structure\n",
    "hansard_bandt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4388037d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'gid': '2021-10-27.125.1', 'hdate': '2021-10-27', 'htype': '12', 'major': '1', 'section_id': '780809', 'subsection_id': '780810', 'relevance': 28, 'speaker_id': '600', 'hpos': '268', 'body': \"Finally, after eight years, a piece of legislation that might actually do something good for renewables. Why did it take eight years? Could it be because the energy minister, whos in charge of this legislation&#8212;but doesn't have the courage to come and sit here at the dispatch box, so he leaves it up to his junior to come in to fly the flag&#8212;earned his political stripes campaigning...\", 'listurl': '/debates/?id=2021-10-27.116.2&amp;s=speaker%3A10734#g125.1', 'speaker': {'member_id': '600', 'title': '', 'first_name': 'Adam', 'last_name': 'Bandt', 'house': '1', 'constituency': 'Melbourne', 'party': 'Australian Greens', 'person_id': '10734', 'url': '/mp/?m=600'}, 'parent': {'body': 'Bills: Offshore Electricity Infrastructure Bill 2021, Offshore Electricity Infrastructure (Regulatory Levies) Bill 2021, Offshore Electricity Infrastructure (Consequential Amendments) Bill 2021; Second Reading'}}, {'gid': '2021-10-27.139.2', 'hdate': '2021-10-27', 'htype': '12', 'major': '1', 'section_id': '780844', 'subsection_id': '780854', 'relevance': 65, 'speaker_id': '600', 'hpos': '295', 'body': \"I rise today to express my and the Greenss strong support for the two requests in the 'Noise pollution from Brisbane Airports flight path' petition that tabled in this place in October. The 2,455 signatories had two reasonable requests: 1. Amend the Air Services Act 1995 to free Airservices Australia from its regulatory capture by the aviation industry and ensure it protects the human and...\", 'listurl': '/debates/?id=2021-10-27.139.1&amp;s=speaker%3A10734#g139.2', 'speaker': {'member_id': '600', 'title': '', 'first_name': 'Adam', 'last_name': 'Bandt', 'house': '1', 'constituency': 'Melbourne', 'party': 'Australian Greens', 'person_id': '10734', 'url': '/mp/?m=600'}, 'parent': {'body': 'Constituency Statements: Brisbane Airport, Asylum Seekers'}}, {'gid': '2021-10-26.121.1', 'hdate': '2021-10-26', 'htype': '12', 'major': '1', 'section_id': '780468', 'subsection_id': '780484', 'relevance': 39, 'speaker_id': '600', 'hpos': '271', 'body': 'I rise to make a few short comments on the Territories Stolen Generations Redress Scheme (Facilitation) Bill 2021. When the bill proceeds to the Senate, this matter will be taken up further by our First Nations spokesperson, Senator Lydia Thorpe. In making these comments today I begin by acknowledging the traditional owners of the country on which we are meeting today here in Canberra, the...', 'listurl': '/debates/?id=2021-10-26.117.1&amp;s=speaker%3A10734#g121.1', 'speaker': {'member_id': '600', 'title': '', 'first_name': 'Adam', 'last_name': 'Bandt', 'house': '1', 'constituency': 'Melbourne', 'party': 'Australian Greens', 'person_id': '10734', 'url': '/mp/?m=600'}, 'parent': {'body': 'Bills: Territories Stolen Generations Redress Scheme (Facilitation) Bill 2021, Territories Stolen Generations Redress Scheme (Consequential Amendments) Bill 2021; Second Reading'}}]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 3 rows\n",
    "print(hansard_bandt['rows'][:3])\n",
    "\n",
    "# Printing out the rows shows us that 'listurl' is where we will find the webpages to scrape the debates\n",
    "# However, it is a partial url and we need to define the prefix:\n",
    "URL_BASE = 'https://www.openaustralia.org'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54c2b77",
   "metadata": {},
   "source": [
    "### Debate Snippets\n",
    "\n",
    "Snippets of the whole debate are stored under the key 'body' in each row that's been printed. We can use these snippets to narrow down which debate we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb75a688",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gid': '2021-10-25.18.2', 'hdate': '2021-10-25', 'htype': '12', 'major': '1', 'section_id': '779732', 'subsection_id': '779751', 'relevance': 35, 'speaker_id': '600', 'hpos': '44', 'body': 'I move: That this bill be now read a second time. With our coal and gas exports, Australia is the worlds third-biggest exporter of fossil-fuel pollution after Russia and Saudi Arabia, who are coincidentally our only allies in the upcoming climate negotiations in Glasgow. Four-fifths of the coal we extract, we export overseas. This is Australias biggest contribution to the climate emergency...', 'listurl': '/debates/?id=2021-10-25.18.1&amp;s=speaker%3A10734#g18.2', 'speaker': {'member_id': '600', 'title': '', 'first_name': 'Adam', 'last_name': 'Bandt', 'house': '1', 'constituency': 'Melbourne', 'party': 'Australian Greens', 'person_id': '10734', 'url': '/mp/?m=600'}, 'parent': {'body': 'Bills: Coal Prohibition (Quit Coal) Bill 2021; Second Reading'}}\n"
     ]
    }
   ],
   "source": [
    "# Define key_words to look for in the debate snippet\n",
    "key_words = ['pollution', 'climate', 'fossil-fuel']\n",
    "# Define a variable to save the list of debates we've narrowed down\n",
    "speeches = list()\n",
    "\n",
    "# Traverse the data and filter out the debates have the key_words\n",
    "for row in hansard_bandt['rows']:\n",
    "    if all(word in row['body'].lower() for word in key_words):\n",
    "        # Save the url in the variable 'speeches'\n",
    "        speeches.append(URL_BASE+row['listurl'])\n",
    "        # Print the row as we find them\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e4fecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.openaustralia.org/debates/?id=2021-10-25.18.1&amp;s=speaker%3A10734#g18.2']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the contents of the 'speeches' variable\n",
    "speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2c335",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Try it Yourself</b>\n",
    "<ul>    \n",
    "<li> Check out how many results you get in 'speeches' when you change the 'key_words' </li>\n",
    "<li> Within the for-loop above, there is the conditional if-clause. What would happen if you changed 'all()' to 'any()' in this condition?</li>\n",
    "</ul> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc226f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is only one speech so let's save that\n",
    "speech_url = speeches[0]\n",
    "speech_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce5a51",
   "metadata": {},
   "source": [
    "## Scraping\n",
    "\n",
    "We'll be using Beautiful Soup to help us scrape the text from the webpage 'speech_url'. This library is designed for extracting data from html and xml documents. It parses the html/xml and then allows you to traverse the embedded structure.\n",
    "\n",
    "You can learn more about Beautiful Soup here: https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries to retrieve the webpage and scrape it\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Retrieve the webpage (html)\n",
    "url_response = get(speech_url)\n",
    "speech_html = url_response.text\n",
    "\n",
    "# Print the first 1000 characters\n",
    "speech_html[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f457fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the webpage and save it as 'page'\n",
    "page = BeautifulSoup(speech_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f395b9",
   "metadata": {},
   "source": [
    "### Beautiful But Not Magical\n",
    "\n",
    "There are no magic tricks when it comes to webpage scraping and while Beautiful Soup is a great tool for scraping text from a webpage, you need to encode what to scrape.\n",
    "\n",
    "One way to do this is to inspect the html to find what you want to scrape. Luckily there are conventions, such as the tag ```<p/>``` being used to encode paragraphs.\n",
    "\n",
    "In this html page we see the these paragraph are normally inside a ```<p/>``` class labelled \"speaker\", so our first step would be to find this ```<p/>``` section, and then we can iterate over all the other non-labelled paragraphs ```<p/>``` and extract the text from it.\n",
    "\n",
    "The algorithm above won't be the same for every webpage you encounter, which is why it's a good idea to inspect the html source that you want to scrape. This might seem like overkill for one webpage but if you want to do this for hundreds of pages, it's worthwhile!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9874f",
   "metadata": {},
   "source": [
    "Different browsers have different ways to inspect the html source, and a quick search web search will help you find out how.\n",
    "\n",
    "<img src=\"https://github.com/Australian-Text-Analytics-Platform/web-scraping/blob/main/img/bandt-oa.png?raw=true\" class=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caddfae2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# In the Beautiful Soup object 'page' find \n",
    "labelled = page.find('p', class_=\"speaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ea2f3",
   "metadata": {},
   "source": [
    "The word “class” is a reserved word in Python, so if you use ```class``` as an argument you will get a syntax error. Instead you can search for the item \"class\" using the keyword ```class_``` in Beautiful Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c17697",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = list()\n",
    "paragraphs = labelled.find_all('p')\n",
    "for p in paragraphs:\n",
    "    if 'class' not in p.attrs:\n",
    "        motion.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bc7603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out how many paragraphs that were extracted\n",
    "len(motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb1b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I move:',\n",
       " \"With our coal and gas exports, Australia is the world's third-biggest exporter of fossil-fuel pollution after Russia and Saudi Arabia, who are coincidentally our only allies in the upcoming climate negotiations in Glasgow.\",\n",
       " \"Four-fifths of the coal we extract, we export overseas. This is Australia's biggest contribution to the climate emergency that our carbon accounts exclude and our establishment political parties ignore.\",\n",
       " 'But, without a plan for coal, there is no plan to stop runaway global heating.',\n",
       " 'Almost all of our exports go to Japan, China, and South Korea. All three have pledged net zero, which means the first thing they will target is pushing thermal coal out of their electricity system.',\n",
       " 'Either we plan the transformation out of coal—on our own terms—or we let other countries make the decision for us, without warning.',\n",
       " \"We are at a crossroads and right now we're staring down the wrong path. On the eve of the Glasgow climate summit, while the rest of the world are making plans to get out of coal and gas, here we have the Liberal and Labor parties backing more coal and gas—including the Northern Territory Labor government approving fracking in the Beetaloo basin just last week.\",\n",
       " \"The Prime Minister has said we shouldn't be afraid of coal, and just last week Labor's climate spokesperson said Labor won't stand in the way of more coal exports, pushing the same 'drug dealer's defence' that Tony Abbott did: if we don't sell it to you, you'll get it from somewhere else.\",\n",
       " \"Imagine if we'd said that about asbestos. But Labor and Liberal keep taking donations from the coal and gas corporations and keep selling a product that causes our country harm.\",\n",
       " 'Every extra molecule of coal, oil and gas that gets burned makes global warming worse and harms Australia.']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each paragraph is saved as an element in the list\n",
    "# Print out the first 10 paragraphs\n",
    "motion[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58daffb1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Try it Yourself</b>\n",
    "\n",
    "In this notebook we scraped the debate text from the page. There is a lot more information contained in this webpage to scrape!\n",
    "\n",
    "For example you can:\n",
    "<ul>    \n",
    "<li> Extract the names of the politicians involved in this motion.</li>\n",
    "<li> Find out which electorate each of the politicians represent.</li>\n",
    "</ul> \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
